{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0e-5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Symbolics\n",
    "using Latexify\n",
    "using Line\n",
    "\n",
    "include(\"../data/probe_token.jl\")\n",
    "include(\"../data/pre_norm.jl\")\n",
    "\n",
    "N=512\n",
    "\n",
    "μ(x) = sum(x) / N\n",
    "E(x) = μ(x) \n",
    "\n",
    "c(x) = x .- μ(x)\n",
    "\n",
    "#var(x) = sum(c(x) .^2 )\n",
    "#var(x) = sum((x .- μ(x)) .^2 )\n",
    "var(x) = sum((x .- μ(x)) .^2 )/N\n",
    "\n",
    "ϵ = 1e-5\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ReExaminingLayerNorm.ipynb](https://colab.research.google.com/drive/1S39-w4vzX3VzZx_27X_BtrLs442pOJnJ) (also [described on LessWrong](https://www.lesswrong.com/posts/jfG6vdJZCwTQmG7kb/re-examining-layernorm) ) describes the following as definition for layer-norm from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LN (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LN(x) = (x .- E(x))/sqrt(var(x) + ϵ) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is equivalent this should return 11.4077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.407851912178797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias = 0.8328\n",
    "\n",
    "final_residual = LN(pre_norm)\n",
    "\n",
    "logit = sum(.*(probe_token, final_residual)) + bias\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u_ϵ (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm(x) = sqrt(sum(x .^ 2))\n",
    "u_ϵ(x) = x .* (1/sqrt(norm(x)^2 + ϵ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sqrt{n} \\cdot u_{n \\epsilon}(x) = \\frac{x}{\\sqrt{\\textrm{Var}[x] + \\epsilon}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.40785559974425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_residual = sqrt(512) .* u_ϵ(pre_norm)\n",
    "\n",
    "\n",
    "logit = sum(.*(probe_token, final_residual)) + bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$LN = \\sqrt{n} \\cdot U_{n \\epsilon}(c(x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.407851912178797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_nϵ(x) = x .* (1/sqrt(norm(x)^2 + (512*ϵ)) )\n",
    "\n",
    "\n",
    "final_residual = sqrt(512) .* u_nϵ(c(pre_norm))\n",
    "\n",
    "\n",
    "logit = sum(.*(probe_token, final_residual)) + bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying layer normalization results in a vector of approx unit length, in the direction of the centered vector.\n",
    "\n",
    "$$LN v2 = u_{N \\epsilon}(c(v2))$$\n",
    "\n",
    "$$μ(v) = (v ⋅ \\vec{1}) * \\frac{1}{N} \n",
    "    = |v| . \\frac{\\sqrt{N}}{N} . \\cos{\\theta_{v,\\vec{1}}} \n",
    "    = \\frac{|v|. \\cos{\\theta_{v,\\vec{1}}}}{\\sqrt{N}} $$\n",
    "\n",
    "$$c(v) = v - (\\vec{1} * μ(v))$$\n",
    "\n",
    "which is $v$ with the $\\vec{1}$ component cancelled out.\n",
    "\n",
    "The inner product between 2 vectors, with LN applied to the second\n",
    "$$\\bra{v1} \\ket{LN v2} \\approx |v1| \\cos{\\theta_{v1,c(v2)}} $$\n",
    "\n",
    "If $v1$ is understood as the sum of several vectors, they can be analysed in terms of\n",
    "how they contribute to the angle of the centered vector.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
